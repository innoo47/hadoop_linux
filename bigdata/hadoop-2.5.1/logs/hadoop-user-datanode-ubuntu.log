2024-07-25 23:22:07,583 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/user/hadoop-2.5.1/etc/hadoop:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/user/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 2e18d179e4a8065b6a9f29cf2de9451891265cce; compiled by 'jenkins' on 2014-09-05T23:11Z
STARTUP_MSG:   java = 1.8.0_362
************************************************************/
2024-07-25 23:22:07,588 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-07-25 23:22:07,898 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-07-25 23:22:07,959 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-07-25 23:22:07,959 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-07-25 23:22:07,961 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2024-07-25 23:22:07,962 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-07-25 23:22:08,008 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-07-25 23:22:08,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-07-25 23:22:08,010 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-07-25 23:22:08,057 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-07-25 23:22:08,060 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-07-25 23:22:08,066 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-07-25 23:22:08,068 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-07-25 23:22:08,068 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-25 23:22:08,068 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-25 23:22:08,078 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2024-07-25 23:22:08,079 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2024-07-25 23:22:08,079 INFO org.mortbay.log: jetty-6.1.26
2024-07-25 23:22:08,227 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2024-07-25 23:22:08,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = user
2024-07-25 23:22:08,246 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-07-25 23:22:08,269 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-07-25 23:22:08,280 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-07-25 23:22:08,336 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-07-25 23:22:08,342 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-07-25 23:22:08,352 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2024-07-25 23:22:08,453 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2024-07-25 23:22:08,453 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2024-07-25 23:22:08,453 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2024-07-25 23:22:08,453 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2024-07-25 23:22:08,454 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2024-07-25 23:22:08,456 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2024-07-25 23:22:08,457 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddresses(DFSUtil.java:796)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:791)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:292)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1895)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1782)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1829)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2005)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2029)
2024-07-25 23:22:08,458 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2024-07-25 23:22:08,459 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2024-07-25 23:37:19,114 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/user/hadoop-2.5.1/etc/hadoop:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/user/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/user/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 2e18d179e4a8065b6a9f29cf2de9451891265cce; compiled by 'jenkins' on 2014-09-05T23:11Z
STARTUP_MSG:   java = 1.8.0_362
************************************************************/
2024-07-25 23:37:19,119 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-07-25 23:37:19,384 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-07-25 23:37:19,470 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-07-25 23:37:19,470 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-07-25 23:37:19,473 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2024-07-25 23:37:19,474 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-07-25 23:37:19,493 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-07-25 23:37:19,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-07-25 23:37:19,495 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-07-25 23:37:19,563 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-07-25 23:37:19,566 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-07-25 23:37:19,581 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-07-25 23:37:19,583 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-07-25 23:37:19,583 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-25 23:37:19,583 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-25 23:37:19,601 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2024-07-25 23:37:19,603 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2024-07-25 23:37:19,603 INFO org.mortbay.log: jetty-6.1.26
2024-07-25 23:37:19,755 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2024-07-25 23:37:19,785 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = user
2024-07-25 23:37:19,786 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-07-25 23:37:19,811 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-07-25 23:37:19,822 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-07-25 23:37:19,846 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-07-25 23:37:19,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-07-25 23:37:19,883 INFO org.mortbay.log: Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2024-07-25 23:37:19,984 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Waiting for threadgroup to exit, active threads is 0
2024-07-25 23:37:19,984 INFO org.apache.hadoop.ipc.Server: Stopping server on 50020
2024-07-25 23:37:19,985 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Stopping DataNode metrics system...
2024-07-25 23:37:19,985 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system stopped.
2024-07-25 23:37:19,985 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system shutdown complete.
2024-07-25 23:37:19,988 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Shutdown complete.
2024-07-25 23:37:19,988 FATAL org.apache.hadoop.hdfs.server.datanode.DataNode: Exception in secureMain
java.io.IOException: Incorrect configuration: namenode address dfs.namenode.servicerpc-address or dfs.namenode.rpc-address is not configured.
	at org.apache.hadoop.hdfs.DFSUtil.getNNServiceRpcAddresses(DFSUtil.java:796)
	at org.apache.hadoop.hdfs.server.datanode.BlockPoolManager.refreshNamenodes(BlockPoolManager.java:155)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:791)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:292)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:1895)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:1782)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.createDataNode(DataNode.java:1829)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.secureMain(DataNode.java:2005)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.main(DataNode.java:2029)
2024-07-25 23:37:19,989 INFO org.apache.hadoop.util.ExitUtil: Exiting with status 1
2024-07-25 23:37:19,990 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2024-07-28 22:41:17,442 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/user/bigdata/hadoop-2.5.1/etc/hadoop:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 2e18d179e4a8065b6a9f29cf2de9451891265cce; compiled by 'jenkins' on 2014-09-05T23:11Z
STARTUP_MSG:   java = 1.8.0_362
************************************************************/
2024-07-28 22:41:17,448 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-07-28 22:41:17,748 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-07-28 22:41:17,812 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-07-28 22:41:17,812 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-07-28 22:41:17,833 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2024-07-28 22:41:17,834 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-07-28 22:41:17,849 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-07-28 22:41:17,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-07-28 22:41:17,851 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-07-28 22:41:17,892 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-07-28 22:41:17,894 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-07-28 22:41:17,901 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-07-28 22:41:17,903 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-07-28 22:41:17,903 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-28 22:41:17,903 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-28 22:41:17,919 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2024-07-28 22:41:17,921 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2024-07-28 22:41:17,921 INFO org.mortbay.log: jetty-6.1.26
2024-07-28 22:41:18,013 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2024-07-28 22:41:18,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = user
2024-07-28 22:41:18,034 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-07-28 22:41:18,055 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-07-28 22:41:18,065 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-07-28 22:41:18,103 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-07-28 22:41:18,109 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-07-28 22:41:18,120 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-07-28 22:41:18,125 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2024-07-28 22:41:18,128 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-07-28 22:41:18,129 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-07-28 22:41:19,178 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:20,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:21,179 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:22,180 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:23,181 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:24,182 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:25,183 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:26,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:27,184 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:28,185 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:28,187 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:41:34,188 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:35,189 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:36,190 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:37,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:38,191 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:39,192 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:40,193 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:41,194 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:42,195 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:43,196 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:43,197 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:41:49,199 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:50,200 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:51,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:52,201 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:53,202 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:54,203 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:55,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:56,205 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:57,206 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:58,207 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:41:58,207 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:42:04,209 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:05,210 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:06,211 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:07,212 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:08,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:09,213 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:10,214 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:11,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:12,215 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:13,216 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:13,217 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:42:19,218 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:20,219 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:21,220 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:22,221 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:23,222 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:24,223 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:25,224 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:26,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:27,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:28,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:28,227 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:42:34,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:35,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:36,230 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:37,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:38,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:39,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:40,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:41,234 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:42,235 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:43,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:43,236 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:42:49,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:50,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:51,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:52,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:53,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:54,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:55,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:56,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:57,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:58,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:42:58,245 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:43:04,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:05,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:06,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:07,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:08,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:09,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:10,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:11,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:12,252 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:13,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:13,254 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:43:19,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:20,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:21,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:22,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:23,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:24,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:25,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:26,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:27,262 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:28,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:28,264 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:43:34,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:35,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:36,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:37,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:38,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:39,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:40,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:41,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:42,271 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:43,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:43,273 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:43:49,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:50,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:51,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:52,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:53,280 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:54,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:55,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:56,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:57,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:58,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:43:58,286 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:44:04,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:05,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:06,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:07,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:08,290 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:09,292 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:10,293 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:11,294 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:12,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:13,295 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:13,296 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:44:19,298 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:20,299 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:21,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:22,300 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:23,301 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:24,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:25,302 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:26,303 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:27,304 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:28,305 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:28,306 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:44:34,308 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:35,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:36,309 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:37,310 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:38,311 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:39,312 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:40,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:41,313 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:42,314 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:43,315 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:43,315 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:44:49,317 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:50,318 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:51,319 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:52,320 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:53,321 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:54,322 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:55,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:56,323 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:57,324 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:58,325 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:44:58,326 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:45:04,327 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:05,328 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:06,329 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:07,330 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:08,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:09,331 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:10,332 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:11,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:12,333 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:13,334 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:13,335 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:45:19,337 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:20,338 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:21,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:22,339 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:23,340 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:24,341 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:25,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:26,342 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:27,343 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:28,344 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:28,345 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:45:34,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:35,347 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:36,348 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:37,349 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:38,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:39,350 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:40,351 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:41,352 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:42,353 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:43,354 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:43,354 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:45:49,356 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:50,357 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:51,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:52,358 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:53,359 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:54,360 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:55,361 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:56,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:57,362 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:58,363 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:45:58,364 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:46:04,365 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:05,366 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:06,367 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:07,368 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:08,369 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:09,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:10,370 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:11,371 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:12,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:13,373 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:13,374 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:46:19,375 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:20,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:21,376 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:22,377 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:23,378 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:24,379 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:25,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:26,380 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:27,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:28,381 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:28,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:46:34,384 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:35,385 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:36,386 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:37,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:38,387 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:39,388 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:40,389 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:41,390 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:42,391 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:43,392 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:43,393 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:46:49,394 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:50,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:51,395 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:52,396 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:53,397 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:54,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:55,398 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:56,399 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:57,400 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:58,401 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:46:58,402 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:47:04,403 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:05,404 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:06,405 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:07,406 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:08,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:09,407 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:10,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:11,408 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:12,409 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:13,410 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:13,411 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:47:19,412 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:20,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:21,413 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:22,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:23,414 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:24,415 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:25,416 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:26,417 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:27,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:28,418 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:28,419 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:47:34,420 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:35,421 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:36,422 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:37,423 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:38,424 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:39,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:40,425 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:41,426 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:42,427 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:43,428 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:43,428 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:47:49,430 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:50,431 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:51,432 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:52,433 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:53,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:54,434 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:55,435 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:56,436 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:57,437 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:58,438 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:47:58,438 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:48:04,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:05,440 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:06,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:07,441 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:08,442 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:09,443 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:10,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:11,444 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:12,445 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:13,446 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:13,446 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:48:19,447 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:20,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:21,448 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:22,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:23,449 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:24,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:25,450 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:26,451 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:27,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:28,452 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:28,453 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:48:34,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:35,455 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:36,456 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:37,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:38,457 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:39,458 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:40,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:41,459 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:42,460 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:43,461 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:43,461 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:48:49,462 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:50,463 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:51,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:52,464 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:53,465 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:54,466 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:55,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:56,467 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:57,468 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:58,469 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:48:58,470 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:49:04,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:05,471 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:06,472 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:07,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:08,473 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:09,474 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:10,475 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:11,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:12,476 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:13,477 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:13,477 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:49:15,345 ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
2024-07-28 22:49:15,347 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down DataNode at ubuntu/127.0.1.1
************************************************************/
2024-07-28 22:49:39,526 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = ubuntu/127.0.1.1
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 2.5.1
STARTUP_MSG:   classpath = /home/user/bigdata/hadoop-2.5.1/etc/hadoop:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-net-3.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/avro-1.7.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/activation-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jsch-0.1.42.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/xz-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/hadoop-annotations-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/junit-4.11.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/paranamer-2.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/hadoop-auth-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/commons-el-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/guava-11.0.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jersey-json-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/lib/jettison-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/hadoop-common-2.5.1-tests.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/common/hadoop-nfs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-nfs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/hdfs/hadoop-hdfs-2.5.1-tests.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/activation-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/xz-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/guice-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/lib/jettison-1.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-client-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-tests-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-api-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/hadoop-annotations-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.5.1.jar:/home/user/bigdata/hadoop-2.5.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.5.1-tests.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar:/contrib/capacity-scheduler/*.jar
STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r 2e18d179e4a8065b6a9f29cf2de9451891265cce; compiled by 'jenkins' on 2014-09-05T23:11Z
STARTUP_MSG:   java = 1.8.0_362
************************************************************/
2024-07-28 22:49:39,532 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2024-07-28 22:49:39,813 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2024-07-28 22:49:39,875 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
2024-07-28 22:49:39,875 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2024-07-28 22:49:39,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is ubuntu
2024-07-28 22:49:39,878 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2024-07-28 22:49:39,892 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:50010
2024-07-28 22:49:39,894 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwith is 1048576 bytes/s
2024-07-28 22:49:39,895 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 5
2024-07-28 22:49:39,938 INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
2024-07-28 22:49:39,940 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2024-07-28 22:49:39,947 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2024-07-28 22:49:39,949 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2024-07-28 22:49:39,949 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2024-07-28 22:49:39,949 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2024-07-28 22:49:39,958 INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.datanode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2024-07-28 22:49:39,960 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 50075
2024-07-28 22:49:39,960 INFO org.mortbay.log: jetty-6.1.26
2024-07-28 22:49:40,075 INFO org.mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50075
2024-07-28 22:49:40,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = user
2024-07-28 22:49:40,096 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2024-07-28 22:49:40,118 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue class java.util.concurrent.LinkedBlockingQueue
2024-07-28 22:49:40,128 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 50020
2024-07-28 22:49:40,144 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:50020
2024-07-28 22:49:40,150 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
2024-07-28 22:49:40,171 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
2024-07-28 22:49:40,176 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
2024-07-28 22:49:40,178 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2024-07-28 22:49:40,179 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 50020: starting
2024-07-28 22:49:41,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:42,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:43,226 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:44,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:45,228 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:46,229 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:47,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:48,231 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:49,232 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:50,233 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:50,235 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:49:56,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:57,236 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:58,237 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:49:59,238 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:00,239 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:01,240 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:02,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:03,241 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:04,242 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:05,243 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:05,243 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:50:11,244 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:12,245 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:13,246 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:14,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:15,247 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:16,248 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:17,249 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:18,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:19,250 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:20,251 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:20,252 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:50:26,253 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:27,254 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:28,255 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:29,256 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:30,257 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:31,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:32,258 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:33,259 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:34,260 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:35,261 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:35,262 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:50:41,263 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:42,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:43,264 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:44,265 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:45,266 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:46,267 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:47,268 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:48,269 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:49,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:50,270 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:50,271 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:50:56,272 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:57,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:58,273 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:50:59,274 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:00,275 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:01,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:02,276 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:03,277 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:04,278 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:05,279 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:05,280 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:51:11,281 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:12,282 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:13,283 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:14,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:15,284 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:16,285 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:17,286 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:18,287 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:19,288 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:20,289 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:20,289 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: Problem connecting to server: localhost/127.0.0.1:9000
2024-07-28 22:51:26,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:27,291 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: localhost/127.0.0.1:9000. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2024-07-28 22:51:27,446 INFO org.apache.hadoop.hdfs.server.common.Storage: Data-node version: -55 and name-node layout version: -57
2024-07-28 22:51:27,450 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-user/dfs/data/in_use.lock acquired by nodename 20242@ubuntu
2024-07-28 22:51:27,450 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-user/dfs/data is not formatted
2024-07-28 22:51:27,450 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-07-28 22:51:27,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-898549557-127.0.1.1-1722232274627
2024-07-28 22:51:27,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled
2024-07-28 22:51:27,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-user/dfs/data/current/BP-898549557-127.0.1.1-1722232274627 is not formatted.
2024-07-28 22:51:27,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting ...
2024-07-28 22:51:27,487 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-898549557-127.0.1.1-1722232274627 directory /tmp/hadoop-user/dfs/data/current/BP-898549557-127.0.1.1-1722232274627/current
2024-07-28 22:51:27,488 INFO org.apache.hadoop.hdfs.server.common.Storage: Restored 0 block files from trash.
2024-07-28 22:51:27,489 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1340288288;bpid=BP-898549557-127.0.1.1-1722232274627;lv=-55;nsInfo=lv=-57;cid=CID-4ba46d41-5e1b-455a-b1b6-fb16500c3f1f;nsid=1340288288;c=0;bpid=BP-898549557-127.0.1.1-1722232274627;dnuuid=null
2024-07-28 22:51:27,490 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 108f6eb0-6a69-4da3-bac3-6067dbad7b34
2024-07-28 22:51:27,498 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-user/dfs/data/current, StorageType: DISK
2024-07-28 22:51:27,504 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2024-07-28 22:51:27,507 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1722251375507 with interval 21600000
2024-07-28 22:51:27,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-898549557-127.0.1.1-1722232274627
2024-07-28 22:51:27,508 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-898549557-127.0.1.1-1722232274627 on volume /tmp/hadoop-user/dfs/data/current...
2024-07-28 22:51:27,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-898549557-127.0.1.1-1722232274627 on /tmp/hadoop-user/dfs/data/current: 11ms
2024-07-28 22:51:27,520 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-898549557-127.0.1.1-1722232274627: 12ms
2024-07-28 22:51:27,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-898549557-127.0.1.1-1722232274627 on volume /tmp/hadoop-user/dfs/data/current...
2024-07-28 22:51:27,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-898549557-127.0.1.1-1722232274627 on volume /tmp/hadoop-user/dfs/data/current: 1ms
2024-07-28 22:51:27,521 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 1ms
2024-07-28 22:51:27,523 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-898549557-127.0.1.1-1722232274627 (Datanode Uuid null) service to localhost/127.0.0.1:9000 beginning handshake with NN
2024-07-28 22:51:27,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-898549557-127.0.1.1-1722232274627 (Datanode Uuid null) service to localhost/127.0.0.1:9000 successfully registered with NN
2024-07-28 22:51:27,551 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using DELETEREPORT_INTERVAL of 300000 msec  BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2024-07-28 22:51:27,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-898549557-127.0.1.1-1722232274627 (Datanode Uuid 108f6eb0-6a69-4da3-bac3-6067dbad7b34) service to localhost/127.0.0.1:9000 trying to claim ACTIVE state with txid=1
2024-07-28 22:51:27,603 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-898549557-127.0.1.1-1722232274627 (Datanode Uuid 108f6eb0-6a69-4da3-bac3-6067dbad7b34) service to localhost/127.0.0.1:9000
2024-07-28 22:51:27,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Sent 1 blockreports 0 blocks total. Took 1 msec to generate and 73 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@787586b2
2024-07-28 22:51:27,678 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-898549557-127.0.1.1-1722232274627
2024-07-28 22:51:27,681 INFO org.apache.hadoop.util.GSet: Computing capacity for map BlockMap
2024-07-28 22:51:27,681 INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
2024-07-28 22:51:27,682 INFO org.apache.hadoop.util.GSet: 0.5% max memory 889 MB = 4.4 MB
2024-07-28 22:51:27,682 INFO org.apache.hadoop.util.GSet: capacity      = 2^19 = 524288 entries
2024-07-28 22:51:27,683 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Periodic Block Verification Scanner initialized with interval 504 hours for block pool BP-898549557-127.0.1.1-1722232274627
2024-07-28 22:51:27,685 INFO org.apache.hadoop.hdfs.server.datanode.DataBlockScanner: Added bpid=BP-898549557-127.0.1.1-1722232274627 to blockPoolScannerMap, new size=1
2024-07-28 23:32:57,871 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-898549557-127.0.1.1-1722232274627:blk_1073741825_1001 src: /127.0.0.1:50014 dest: /127.0.0.1:50010
2024-07-28 23:32:57,949 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50014, dest: /127.0.0.1:50010, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_555039240_1, offset: 0, srvID: 108f6eb0-6a69-4da3-bac3-6067dbad7b34, blockid: BP-898549557-127.0.1.1-1722232274627:blk_1073741825_1001, duration: 56932376
2024-07-28 23:32:57,950 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-898549557-127.0.1.1-1722232274627:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-07-28 23:33:02,708 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-898549557-127.0.1.1-1722232274627:blk_1073741825_1001
2024-07-28 23:33:16,374 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50010, dest: /127.0.0.1:52834, bytes: 18, op: HDFS_READ, cliID: DFSClient_NONMAPREDUCE_1379456722_18, offset: 0, srvID: 108f6eb0-6a69-4da3-bac3-6067dbad7b34, blockid: BP-898549557-127.0.1.1-1722232274627:blk_1073741825_1001, duration: 24068108
2024-07-28 23:35:04,519 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-898549557-127.0.1.1-1722232274627:blk_1073741826_1002 src: /127.0.0.1:52214 dest: /127.0.0.1:50010
2024-07-28 23:35:04,546 INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:52214, dest: /127.0.0.1:50010, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_104684685_1, offset: 0, srvID: 108f6eb0-6a69-4da3-bac3-6067dbad7b34, blockid: BP-898549557-127.0.1.1-1722232274627:blk_1073741826_1002, duration: 23950995
2024-07-28 23:35:04,547 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-898549557-127.0.1.1-1722232274627:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
2024-07-28 23:35:07,744 INFO org.apache.hadoop.hdfs.server.datanode.BlockPoolSliceScanner: Verification succeeded for BP-898549557-127.0.1.1-1722232274627:blk_1073741826_1002
2024-07-28 23:52:46,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Sent 1 blockreports 2 blocks total. Took 1 msec to generate and 3 msecs for RPC and NN processing.  Got back commands org.apache.hadoop.hdfs.server.protocol.FinalizeCommand@25af6359
2024-07-28 23:52:46,017 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-898549557-127.0.1.1-1722232274627
